{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0661caf3",
   "metadata": {},
   "source": [
    "==================================================================================================================================\n",
    "# <div align=\"center\">PROJECT 03: Etsy Print-On-Demand Trends</div>\n",
    "=================================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5dbfaa",
   "metadata": {},
   "source": [
    "### üìù BUSINESS IDEA\n",
    "\n",
    "**Print-On-Demand (POD) Business** ‚Äì What the project is about\n",
    "\n",
    "### ‚ö†Ô∏è PROBLEM\n",
    "\n",
    "No Free API exists to access the market data needed, requiring web scraping to gather insights ‚Äì The challenge we‚Äôre addressing\n",
    "\n",
    "### üî∞ SOLUTION FRAMEWORK\n",
    "\n",
    "Web scrape etsy for a specific POD product\n",
    "\n",
    "Collect the data necessary to clean & analyze\n",
    "\n",
    "\n",
    "| **Development**                                                                                                                                             | **Presentation**                 |\n",
    "| ----------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------- |\n",
    "| **Business Idea** ‚Üí **Problem Definition** ‚Üí **Data Research & Visualization** ‚Üí **Insights** ‚Üí **Interpretation** ‚Üí **Implications** ‚Üí **Business Impact** | **Limitations & Considerations** |\n",
    "\n",
    "### üßê QUESTIONS\n",
    "\n",
    "- Which keywords in product titles and descriptions drive the most sales?\n",
    "\n",
    "- Which product niches have the highest demand?\n",
    "\n",
    "- What keywords improve search visibility on Etsy?\n",
    "\n",
    "- When is the best period to sell based on review trends?\n",
    "\n",
    "- Which price ranges generate the most sales?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c885bb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85381234",
   "metadata": {},
   "source": [
    "### üìì SECTION OVERVIEW\n",
    "\n",
    "- **Project / Business Idea:** What the project is about\n",
    "\n",
    "- **Problem:** The challenge we‚Äôre addressing\n",
    "\n",
    "- **Solution / Approach:** How we solve it\n",
    "\n",
    "- **Research & Plots:** How we analyzed data visually\n",
    "\n",
    "- **Insights:** What we discovered\n",
    "\n",
    "- **Interpretation:** Why it matters\n",
    "\n",
    "- **Implications:** What actions the business can take\n",
    "\n",
    "- **Business Impact:** Expected results for the business\n",
    "\n",
    "- **Limitations:** What constraints or gaps exist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db8c099",
   "metadata": {},
   "source": [
    "==================================================================================================================================\n",
    "# <div align=\"center\">RESEARCH</div>\n",
    "=================================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627b7d36",
   "metadata": {},
   "source": [
    "### üåê **Which Are the Best-Selling POD Products on Etsy?**\n",
    "\n",
    "I‚Äôm researching print-on-demand products to sell on Etsy that only require **digital artwork and marketing**, while the POD provider handles **printing, packaging, and shipping**.\n",
    "\n",
    "\n",
    "### ‚≠ê **Using Google Trends for POD Product Research**\n",
    "üí° **Goal:** Identify which POD product category has been searched the most on Google over the past 5 years (2020‚Äì2025).\n",
    "\n",
    "Below is the list of product categories I‚Äôm comparing:\n",
    "\n",
    "### üéØ **Chosen POD product to research is :** `tote bags`\n",
    "\n",
    "| Category              | Subcategories / Examples                                      |\n",
    "|-----------------------|---------------------------------------------------------------|\n",
    "| **Custom Apparel**        | T-shirts, Hoodies, Sweatshirts, Tank tops                     |\n",
    "| **Mug**                   | Ceramic mugs, Color-changing mugs, Espresso mugs, Travel mugs |\n",
    "| **Tote Bag**              | Cotton totes, All-over print totes                            |\n",
    "| **Phone Case**            | iPhone / Samsung cases, Tough / Slim cases                    |\n",
    "| **Stickers**              | Die-cut stickers, Kiss-cut stickers, Sticker sheets           |\n",
    "| **Hats**                  | Baseball caps, Trucker hats, Beanies                          |\n",
    "| **Pillows / Cushions**    | Pillow covers, Stuffed pillows, All-over print pillow designs|\n",
    "| **Blanket**               | Fleece blankets, Sherpa blankets, Woven blankets             |\n",
    "| **Wall Art**              | Posters, Canvas prints, Framed posters, Metal prints         |\n",
    "| **Doormat**               | Printed coir doormats, Rubber-backed doormats                |\n",
    "| **Drinkware**             | Stainless steel tumblers, Water bottles, Wine tumblers       |\n",
    "| **Calendar**              | Custom printed wall calendars                                 |\n",
    "| **Yoga Mat**              | Printed yoga mats                                             |\n",
    "| **Bedding**               | Duvet covers, Pillowcases, All-over print bed sets           |\n",
    "| **Pet Accessories**       | Pet bandanas, Pet beds, Pet bowls, Pet blankets              |\n",
    "| **Ornaments**             | Ceramic ornaments, Wood ornaments, Metal ornaments           |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9d8ffe",
   "metadata": {},
   "source": [
    "==================================================================================================================================\n",
    "# <div align=\"center\">WEB SCRAPING</div>\n",
    "=================================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cbcc66",
   "metadata": {},
   "source": [
    "```Etsy``` is a dynamic website, so scraping it requires careful handling.\n",
    "\n",
    "Since ```Etsy``` uses ```JavaScript``` to load some content,\n",
    "\n",
    "```requests``` +  ``BeautifulSoup`` might work for static parts (like search results), \n",
    "\n",
    "but for dynamic content, ``Selenium`` is more reliable. \n",
    "\n",
    "I will be using ``requests`` + ``BeautifulSoup`` for ```product listings``` **(title, price, link)**\n",
    "\n",
    "Important Note: Etsy uses dynamic loading + anti-bot protections.\n",
    "\n",
    "Using code with standard HTML scraping can work as long as Etsy doesn‚Äôt block the request.\n",
    "\n",
    "If blocked, using headers, rotating proxies, or the Etsy API will be required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b248da7c",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a295521b",
   "metadata": {},
   "source": [
    "### üß∞ **Install for web scraping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7016b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install requests & beautifulsoup\n",
    "!pip install requests beautifulsoup4 fake-useragent pandas\n",
    "\n",
    "# install selenium\n",
    "!pip install selenium pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2372fc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e239d809",
   "metadata": {},
   "source": [
    "### üìå **Avoid web BLOCKED**\n",
    "| Version                                   | Best For          | Pros                                           | Cons                          |\n",
    "| ----------------------------------------- | ----------------- | ---------------------------------------------- | ----------------------------- |\n",
    "| **Requests + BeautifulSoup + Pagination** | Simple scraping   | Fast, clean                                    | Etsy may block request        |\n",
    "| **Selenium + BeautifulSoup + Pagination** | Reliable scraping | Bypasses bot protection, loads dynamic content | Slower, requires ChromeDriver |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bb6fca",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d8c4a8",
   "metadata": {},
   "source": [
    "### üìå **Pagination + BeautifulSoup**\n",
    "| Version                                   | Best For          | Pros                                           | Cons                          |\n",
    "| ----------------------------------------- | ----------------- | ---------------------------------------------- | ----------------------------- |\n",
    "| **Requests + BeautifulSoup + Pagination** | Simple scraping   | Fast, clean                                    | Etsy may block request        |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef6d5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "\n",
    "\n",
    "def scrape_products(pages=5, max_items=10):\n",
    "    base_url = \"https://www.etsy.com/search?q=tote+bag&page=\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120 Safari/537.36\"\n",
    "    }\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for page in range(1, pages + 1):\n",
    "        url = base_url + str(page)\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "        products = soup.find_all(\"li\", class_=\"wt-list-unstyled\")\n",
    "\n",
    "        for item in products:\n",
    "            if len(data) >= max_items:\n",
    "                return pd.DataFrame(data)\n",
    "\n",
    "            # URL\n",
    "            link = item.find(\"a\", href=True)\n",
    "            if not link:\n",
    "                continue\n",
    "            product_url = \"https://www.etsy.com\" + link[\"href\"]\n",
    "\n",
    "            # Title\n",
    "            title_tag = item.find(\"h3\")\n",
    "            title = title_tag.get_text(strip=True) if title_tag else None\n",
    "\n",
    "            # Price\n",
    "            price_tag = item.find(\"span\", class_=\"currency-value\")\n",
    "            price = None\n",
    "            if price_tag:\n",
    "                try:\n",
    "                    price = float(price_tag.text.replace(\",\", \".\"))\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            # Rating\n",
    "            rating_tag = item.find(\"span\", class_=\"wt-screen-reader-only\")\n",
    "            rating = None\n",
    "            if rating_tag:\n",
    "                match_rating = re.search(r\"([\\d.]+) out of 5\", rating_tag.text)\n",
    "                if match_rating:\n",
    "                    rating = float(match_rating.group(1))\n",
    "\n",
    "            # Reviews\n",
    "            reviews_tag = item.find(\"span\", class_=\"wt-text-body-01\")\n",
    "            reviews = None\n",
    "            if reviews_tag:\n",
    "                match_reviews = re.search(r\"\\((\\d+)\\)\", reviews_tag.text)\n",
    "                if match_reviews:\n",
    "                    reviews = int(match_reviews.group(1))\n",
    "\n",
    "            # Delivery\n",
    "            delivery = None\n",
    "            delivery_tag = item.find(string=re.compile(\"delivery\", re.I))\n",
    "            if delivery_tag:\n",
    "                txt = delivery_tag.lower()\n",
    "                if \"free\" in txt:\n",
    "                    delivery = 0\n",
    "                else:\n",
    "                    match_del = re.search(r\"‚Ç¨\\s?([\\d.,]+)\", delivery_tag)\n",
    "                    if match_del:\n",
    "                        delivery = float(match_del.group(1).replace(\",\", \".\"))\n",
    "\n",
    "            data.append({\n",
    "                \"URL\": product_url,\n",
    "                \"Title\": title,\n",
    "                \"Price\": price,\n",
    "                \"Rating\": rating,\n",
    "                \"Reviews\": reviews,\n",
    "                \"Delivery\": delivery\n",
    "            })\n",
    "\n",
    "        time.sleep(1)\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# Example: save CSV\n",
    "if __name__ == \"__main__\":\n",
    "    df = scrape_products()\n",
    "    df.to_csv(\"../data/interim/0_interim_price.csv\", index=False)\n",
    "    print(\"STEP 1 : 'Price' INTERIM and CSV saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4470cc92",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861abf5a",
   "metadata": {},
   "source": [
    "### üìå **Selenium-Based (ChromeDriver)**\n",
    "\n",
    "| Version                                   | Best For          | Pros                                           | Cons                          |\n",
    "| ----------------------------------------- | ----------------- | ---------------------------------------------- | ----------------------------- |\n",
    "| **Selenium + BeautifulSoup + Pagination** | Reliable scraping | Bypasses bot protection, loads dynamic content | Slower, requires ChromeDriver |\n",
    "\n",
    "Link to ChromeDriver: https://googlechromelabs.github.io/chrome-for-testing/#stable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7c0062",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "\n",
    "\n",
    "def scrape_products_selenium(max_items=10):\n",
    "    options = Options()\n",
    "    options.add_argument(\"--headless\")  \n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"start-maximized\")\n",
    "    options.add_argument(\"user-agent=Mozilla/5.0\")\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "\n",
    "    data = []\n",
    "    page = 1\n",
    "\n",
    "    while len(data) < max_items:\n",
    "        url = f\"https://www.etsy.com/search?q=tote+bag&page={page}\"\n",
    "        driver.get(url)\n",
    "        time.sleep(4)\n",
    "\n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "        products = soup.find_all(\"li\", class_=\"wt-list-unstyled\")\n",
    "\n",
    "        for item in products:\n",
    "            if len(data) >= max_items:\n",
    "                break\n",
    "\n",
    "            # URL\n",
    "            link = item.find(\"a\", href=True)\n",
    "            if not link:\n",
    "                continue\n",
    "            product_url = \"https://www.etsy.com\" + link[\"href\"]\n",
    "\n",
    "            # Title\n",
    "            title_tag = item.find(\"h3\")\n",
    "            title = title_tag.get_text(strip=True) if title_tag else None\n",
    "\n",
    "            # Price\n",
    "            price_tag = item.find(\"span\", class_=\"currency-value\")\n",
    "            price = None\n",
    "            if price_tag:\n",
    "                try:\n",
    "                    price = float(price_tag.text.replace(\",\", \".\"))\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            # Rating\n",
    "            rating_tag = item.find(\"span\", class_=\"wt-screen-reader-only\")\n",
    "            rating = None\n",
    "            if rating_tag:\n",
    "                match_rating = re.search(r\"([\\d.]+) out of 5\", rating_tag.text)\n",
    "                if match_rating:\n",
    "                    rating = float(match_rating.group(1))\n",
    "\n",
    "            # Reviews\n",
    "            reviews_tag = item.find(\"span\", class_=\"wt-text-body-01\")\n",
    "            reviews = None\n",
    "            if reviews_tag:\n",
    "                match_reviews = re.search(r\"\\((\\d+)\\)\", reviews_tag.text)\n",
    "                if match_reviews:\n",
    "                    reviews = int(match_reviews.group(1))\n",
    "\n",
    "            # Delivery\n",
    "            delivery = None\n",
    "            delivery_tag = item.find(string=re.compile(\"delivery\", re.I))\n",
    "            if delivery_tag:\n",
    "                txt = delivery_tag.lower()\n",
    "                if \"free\" in txt:\n",
    "                    delivery = 0\n",
    "                else:\n",
    "                    match_del = re.search(r\"‚Ç¨\\s?([\\d.,]+)\", delivery_tag)\n",
    "                    if match_del:\n",
    "                        delivery = float(match_del.group(1).replace(\",\", \".\"))\n",
    "\n",
    "            data.append({\n",
    "                \"URL\": product_url,\n",
    "                \"Title\": title,\n",
    "                \"Price\": price,\n",
    "                \"Rating\": rating,\n",
    "                \"Reviews\": reviews,\n",
    "                \"Delivery\": delivery\n",
    "            })\n",
    "\n",
    "        page += 1\n",
    "        time.sleep(2)\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Save CSV\n",
    "if __name__ == \"__main__\":\n",
    "    df = scrape_products_selenium()\n",
    "    df.to_csv(\"../data/interim/1_interim_price.csv\", index=False)\n",
    "    print(\"STEP 1 : 'Price' INTERIM and CSV saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf8b454",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e233e4b",
   "metadata": {},
   "source": [
    "## üìå **Product PAGE**\n",
    "The main data fields to extract from Etsy's product page :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d465a9a",
   "metadata": {},
   "source": [
    "### ‚≠ê **Etsy Product Info**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0ff9de",
   "metadata": {},
   "source": [
    "| Field Name            | Python Data Type       | Concise Definition               | Long Definition                                                                                       |\n",
    "|-----------------------|-----------------------|---------------------------------|-------------------------------------------------------------------------------------------------------|\n",
    "| product_id            | `str`                   | Unique Etsy listing ID.          | Unique identifier assigned by Etsy to each product listing.                                           |\n",
    "| product_title         | `str`                   | Product‚Äôs title.                 | The full title/name of the product as shown on the listing page.                                      |\n",
    "| old_price             | `float` or `Decimal`      | Price before discount.           | The original price before any discounts were applied.                                                 |\n",
    "| discount_percentage   | `float`                 | Discount rate in percent.        | The discount value expressed as a percentage (e.g., 20.0 for 20%).                                    |\n",
    "| now_price             | `float` or `Decimal`      | Price after discount.            | The current price after applying discounts.                                                           |\n",
    "| currency              | `str`                   | Currency code (e.g., USD).       | The currency code used for the product price (e.g., \"USD\", \"EUR\").                                    |\n",
    "| listed_date           | `datetime`              | Date the item was listed.        | The date (and optionally time) when the product was first listed on Etsy.                             |\n",
    "| product_url           | `str`                   | Link to the product page.        | The direct URL link to the Etsy product page.                                                         |\n",
    "| product_description   | `str`                   | Product description text.        | The text description of the product, including details, features, and information provided by seller.|\n",
    "| product_variation     | `list[dict]`            | List of available variations.    | A list of variation options (size, color, material, etc.), each represented as a dictionary.          |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd9f7a6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315208fe",
   "metadata": {},
   "source": [
    "### ‚≠ê **Insighted Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210b3f21",
   "metadata": {},
   "source": [
    "| Field Name                 | Python Data Type       | Concise Definition                               |\n",
    "|---------------------------|-------------------------|---------------------------------------------------|\n",
    "| product_niche             | `str`                     | Product theme or genre (comedy, anime‚Ä¶) based on `product_title` & `product_description`.         |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d958252d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b944ac0b",
   "metadata": {},
   "source": [
    "### ‚≠ê **Etsy Product Reviews (Extra dataset)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc875b7",
   "metadata": {},
   "source": [
    "| Field Name                     | Python Data Type | Concise Definition                         |\n",
    "|-------------------------------|------------------|---------------------------------------------|\n",
    "| product_reviews         | `pd.DataFrame`     | Ratings extracted from all reviews, Dates when each review was posted, Text content of each review.          |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b9e6dc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e45476b",
   "metadata": {},
   "source": [
    "## üìå **CODE**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dff1786",
   "metadata": {},
   "source": [
    "### FR VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c779044a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from itertools import product\n",
    "\n",
    "def get_prices(driver):\n",
    "    \"\"\"\n",
    "    Extract now price, old price, and calculate percentage difference.\n",
    "    Returns: now_price, old_price, percentage_difference\n",
    "    \"\"\"\n",
    "    now_price, old_price = None, None\n",
    "\n",
    "    try:\n",
    "        # Grab all relevant price elements\n",
    "        price_elements = driver.find_elements(By.XPATH, \"//p[contains(@class,'wt-text-title')]/span | //span[contains(@class,'wt-text-strikethrough')]\")\n",
    "        for elem in price_elements:\n",
    "            text = elem.text.strip().replace(\"‚Ç¨\", \"\").replace(\"+\", \"\").replace(\",\", \".\")\n",
    "            try:\n",
    "                value = float(text)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            # Determine if strikethrough -> old price\n",
    "            if \"wt-text-strikethrough\" in elem.get_attribute(\"class\"):\n",
    "                old_price = value\n",
    "            else:\n",
    "                now_price = value\n",
    "\n",
    "        # Fallback if only one price found\n",
    "        if now_price is None and old_price is not None:\n",
    "            now_price = old_price\n",
    "        if old_price is None:\n",
    "            old_price = now_price\n",
    "\n",
    "    except:\n",
    "        now_price, old_price = None, None\n",
    "\n",
    "    # Calculate percentage difference\n",
    "    percentage_difference_price = round((old_price - now_price) / old_price * 100, 2) if old_price and now_price and old_price != now_price else None\n",
    "\n",
    "    return now_price, old_price, percentage_difference_price\n",
    "\n",
    "\n",
    "def scrape_products(limit=10):\n",
    "    driver = uc.Chrome()\n",
    "    driver.maximize_window()\n",
    "    wait = WebDriverWait(driver, 15)\n",
    "\n",
    "    # Search page for tote bags\n",
    "    search_url = \"https://www.etsy.com/fr/search?q=tote+bag\"\n",
    "    driver.get(search_url)\n",
    "    time.sleep(5)\n",
    "\n",
    "    # Collect product links\n",
    "    product_links = wait.until(EC.presence_of_all_elements_located(\n",
    "        (By.XPATH, \"//ul[contains(@class,'wt-grid')]/li//a[@data-listing-id]\"))\n",
    "    )\n",
    "    product_links = [link.get_attribute(\"href\") for link in product_links][:limit]\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for idx, url in enumerate(product_links):\n",
    "        print(f\"[INFO] Scraping product {idx+1}/{len(product_links)}: {url}\")\n",
    "        driver.get(url)\n",
    "        time.sleep(5)\n",
    "\n",
    "        # --- Title ---\n",
    "        try:\n",
    "            title = wait.until(EC.presence_of_element_located((By.XPATH, \"//h1\"))).text.strip()\n",
    "        except:\n",
    "            title = None\n",
    "\n",
    "        # --- Rating ---\n",
    "        try:\n",
    "            rating_elem = driver.find_element(By.XPATH, \"//input[@name='rating']\")\n",
    "            rating = float(rating_elem.get_attribute(\"value\"))\n",
    "        except:\n",
    "            rating = None\n",
    "\n",
    "        # --- Reviews ---\n",
    "        try:\n",
    "            reviews_elem = driver.find_element(By.XPATH, \"//h2[contains(@class,'review-header-text')]\")\n",
    "            txt_reviews = reviews_elem.text.strip()\n",
    "            match = re.search(r\"\\((.*?)\\)\", txt_reviews)\n",
    "            if match:\n",
    "                num_text = match.group(1).strip()\n",
    "                if \"K\" in num_text or \"k\" in num_text:\n",
    "                    num_text = num_text.replace(\"K\", \"\").replace(\"k\", \"\").replace(\",\", \".\")\n",
    "                    nbr_reviews = int(float(num_text) * 1000)\n",
    "                else:\n",
    "                    num_text = num_text.replace(\",\", \"\").replace(\" \", \"\").replace(\".\", \"\")\n",
    "                    nbr_reviews = int(num_text)\n",
    "            else:\n",
    "                nbr_reviews = 0\n",
    "        except:\n",
    "            txt_reviews = None\n",
    "            nbr_reviews = None\n",
    "\n",
    "        # --- Delivery ---\n",
    "        try:\n",
    "            delivery_elem = driver.find_element(By.XPATH, \"//span[contains(text(),'livraison') or contains(text(),'delivery')]\")\n",
    "            delivery_text = delivery_elem.text.strip()\n",
    "            delivery = 0 if \"gratuit\" in delivery_text.lower() or \"free\" in delivery_text.lower() else delivery_text\n",
    "        except:\n",
    "            delivery = None\n",
    "\n",
    "        # --- Variants ---\n",
    "        try:\n",
    "            variant_sections = driver.find_elements(By.XPATH, \"//fieldset[contains(@data-selector,'option')]\")\n",
    "            if not variant_sections:\n",
    "                # Single price\n",
    "                now_price, old_price, percentage_difference_price = get_prices(driver)\n",
    "                results.append({\n",
    "                    \"URL\": url, \"Title\": title, \"Rating\": rating,\n",
    "                    \"txt_reviews\": txt_reviews, \"nbr_reviews\": nbr_reviews,\n",
    "                    \"Delivery\": delivery, \"Option\": None,\n",
    "                    \"Old_Price\": old_price, \"Now_Price\": now_price,\n",
    "                    \"Percentage_Difference_Price\": percentage_difference_price\n",
    "                })\n",
    "            else:\n",
    "                # Handle variants\n",
    "                all_options = []\n",
    "                for section in variant_sections:\n",
    "                    opts = section.find_elements(By.XPATH, \".//button[not(contains(@aria-label,'S√©lectionner'))]\")\n",
    "                    option_names = [opt.get_attribute(\"aria-label\") or opt.text for opt in opts]\n",
    "                    all_options.append(option_names)\n",
    "\n",
    "                # Generate all combinations\n",
    "                for combo in product(*all_options):\n",
    "                    try:\n",
    "                        # Click each option\n",
    "                        for sec_idx, option_name in enumerate(combo):\n",
    "                            section = driver.find_elements(By.XPATH, \"//fieldset[contains(@data-selector,'option')]\")[sec_idx]\n",
    "                            opt_buttons = section.find_elements(By.XPATH, \".//button[not(contains(@aria-label,'S√©lectionner'))]\")\n",
    "                            for btn in opt_buttons:\n",
    "                                btn_name = btn.get_attribute(\"aria-label\") or btn.text\n",
    "                                if btn_name == option_name:\n",
    "                                    btn.click()\n",
    "                                    time.sleep(2)\n",
    "                                    break\n",
    "\n",
    "                        # Extract prices\n",
    "                        now_price, old_price, percentage_difference_price = get_prices(driver)\n",
    "\n",
    "                        results.append({\n",
    "                            \"URL\": url, \"Title\": title, \"Rating\": rating,\n",
    "                            \"txt_reviews\": txt_reviews, \"nbr_reviews\": nbr_reviews,\n",
    "                            \"Delivery\": delivery, \"Option\": \" | \".join(combo),\n",
    "                            \"Old_Price\": old_price, \"Now_Price\": now_price,\n",
    "                            \"Percentage_Difference_Price\": percentage_difference_price\n",
    "                        })\n",
    "                    except Exception as e:\n",
    "                        print(f\"[WARNING] Could not process combo {combo}: {e}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[WARNING] Variant handling skipped for product {url}: {e}\")\n",
    "\n",
    "    driver.quit()\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = scrape_products(limit=10)\n",
    "    df.to_csv(\"../data/clean/clean_tote_bags.csv\", index=False)\n",
    "    print(\"[SUCCESS] CSV saved!\")\n",
    "    df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20ae272",
   "metadata": {},
   "source": [
    "==================================================================================================================================\n",
    "# <div align=\"center\">DATA CLEANING & ANALYSIS</div>\n",
    "=================================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f53801",
   "metadata": {},
   "source": [
    "#### üóÉÔ∏è **Raw data**\n",
    "\n",
    "- Web scraped data saved in a DataFrame then a CSV file and uploaded to google drive\n",
    "- The df_url has to be a downloadable link to the csv file from google drive\n",
    "- We load the csv to use for data cleaning and analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b562b962",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load RAW DATA CSV\n",
    "df_url = 'link to the dataFrame collected from scraping as a downloadable link from google drive'\n",
    "df_etsy = pd.read_csv(df_url)\n",
    "\n",
    "print(\"STEP 1 : RAW CSV loaded successfully!\")\n",
    "df_etsy.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c19bfc",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa517ddd",
   "metadata": {},
   "source": [
    "#### üóÉÔ∏è **Interim data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caaa5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save INTERIM DATA to CSV\n",
    "df_etsy.to_csv(\"../data/interim/interim_data.csv\", index=False)\n",
    "print(\"STEP 2 : INRTERIM CSV saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae28f7a9",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60838b5b",
   "metadata": {},
   "source": [
    "#### üóÉÔ∏è **Clean data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72bd2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save CLEAN DATA to CSV\n",
    "df_etsy.to_csv(\"../data/clean/clean_data.csv\", index=False)\n",
    "print(\"STEP 3 : CLEAN CSV saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cf6a73",
   "metadata": {},
   "source": [
    "==================================================================================================================================\n",
    "# <div align=\"center\">PLOTS</div>\n",
    "=================================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b182f1df",
   "metadata": {},
   "source": [
    "### üìä PLOT 01:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001cf4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2b068a",
   "metadata": {},
   "source": [
    "### üìä PLOT 02:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa276733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1870d0",
   "metadata": {},
   "source": [
    "### üìä PLOT 03:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8c1a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5536c3",
   "metadata": {},
   "source": [
    "### üìä PLOT 04:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d36191d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07984f8",
   "metadata": {},
   "source": [
    "### üìä PLOT 05:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee723ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399abc24",
   "metadata": {},
   "source": [
    "==================================================================================================================================\n",
    "# <div align=\"center\">INSIGHTS</div>\n",
    "=================================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6361e53a",
   "metadata": {},
   "source": [
    "### üß† INSIGHT 01:\n",
    "Text\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7a05e5",
   "metadata": {},
   "source": [
    "### üß† INSIGHT 02:\n",
    "Text\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cbb21b",
   "metadata": {},
   "source": [
    "### üß† INSIGHT 03:\n",
    "Text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011deb7a",
   "metadata": {},
   "source": [
    "=================================================================================================================================="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
